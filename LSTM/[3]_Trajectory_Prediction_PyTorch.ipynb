{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jetsonai/Working-R-Ssaem/blob/main/LSTM/%5B3%5D_Trajectory_Prediction_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD_LDLFBsdFg"
      },
      "source": [
        "# **PyTorch를 활용한 Vehicle Trajectory Prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf9796K2MeDC"
      },
      "source": [
        "## **데이터 처리를 위한 라이브러리 불러오기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KipSXiPBOF28"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySh9yEaNOAqV"
      },
      "outputs": [],
      "source": [
        "from io import open\n",
        "from os import path\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wfx-_yjBMhrI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIELdPfCOOay"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnmaa4zqokV4"
      },
      "source": [
        "## **PyTorch 라이브러리 불러오기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToOO3xFnna5x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKkjBMMH-CBQ"
      },
      "source": [
        "## **데이터 읽어오기**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "file_id = \"12b_g_IYdHm8JGIKrQ7WU59MHlkuzdjWG\"\n",
        "output_file = \"trajectory-prediction.zip\"  # Replace \"data_file.ext\" with the desired output filename and extension\n",
        "\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_file)"
      ],
      "metadata": {
        "id": "nKaL8OkxWQkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z-7ipumDtES"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/trajectory-prediction.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S81xJHOqPDoV"
      },
      "source": [
        "## **데이터셋 살펴보기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgG-p4cIPFUF"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/WholeVdata2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHmkxrjMPIqX"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjz1z0GJPL3n"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDx9IEBXPRE8"
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xokzR91AOVrQ"
      },
      "source": [
        "## **PyTorch DataLoader 클래스 정의**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu67m8QrOSHK"
      },
      "outputs": [],
      "source": [
        "class TrajectoryDataset(Dataset) :\n",
        "  def __init__(self, csv_path=\"/content/WholeVdata2.csv\") :\n",
        "    # Inheritance\n",
        "    super(TrajectoryDataset, self).__init__()\n",
        "\n",
        "    # Initialize Variable\n",
        "    self.csv_path = csv_path\n",
        "\n",
        "    # store X as a list, each element is a 100*42(len*# attributes) np array [vel_x; vel_y; x; y; acc; angle]*7\n",
        "    # store Y as a list, each element is a 100*4(len*# attributes) np array[vel_x; vel_y; x; y]\n",
        "    self.frames_x, self.frames_y = [], []\n",
        "\n",
        "    # Function-Calling\n",
        "    self.load_data()\n",
        "    self.norm_data()\n",
        "\n",
        "  def __len__(self) :\n",
        "    return len(self.frames_x)\n",
        "\n",
        "  def __getitem__(self, index) :\n",
        "    single_data = self.frames_x[index]\n",
        "    single_label = self.frames_y[index]\n",
        "\n",
        "    return (single_data, single_label)\n",
        "\n",
        "  def load_data(self) :\n",
        "    data_raw = pd.read_csv(self.csv_path)\n",
        "    max_veh_num = np.max(data_raw.Vehicle_ID.unique())\n",
        "    for vid in data_raw.Vehicle_ID.unique() :\n",
        "      print(f\"{vid} and {max_veh_num}\")\n",
        "      frame_ori = data_raw[data_raw.Vehicle_ID == vid]\n",
        "      frame = frame_ori[[\"Local_X\", \"Local_Y\", \"v_Acc\", \"Angle\",\n",
        "                         \"L_rX\", \"L_rY\", \"L_rAcc\", \"L_angle\",\n",
        "                         \"F_rX\", \"F_rY\", \"F_rAcc\", \"F_angle\",\n",
        "                         \"LL_rX\", \"LL_rY\", \"LL_rAcc\", \"LL_angle\",\n",
        "                         \"LF_rX\", \"LF_rY\", \"LF_rAcc\", \"LF_angle\",\n",
        "                         \"RL_rX\", \"RL_rY\", \"RL_rAcc\", \"RL_angle\",\n",
        "                         \"RF_rX\", \"RF_rY\", \"RF_rAcc\", \"RF_angle\"]]\n",
        "      frame = np.asarray(frame)\n",
        "      frame[np.where(frame > 4000)] = 0 # assign all 5000 to 0\n",
        "\n",
        "      # remove anomalies, which has a discontinuious local x or local y\n",
        "      dis = frame[1:,:2] - frame[:-1,:2]\n",
        "      dis = np.sqrt(np.power(dis[:,0],2)+np.power(dis[:,1],2))\n",
        "\n",
        "      index = np.where(dis > 10)\n",
        "      if not (index[0].all) :\n",
        "          continue\n",
        "\n",
        "      # smooth the data column wise\n",
        "      # window size = 5, polynomial order = 3\n",
        "      frame =  scipy.signal.savgol_filter(frame, window_length=5, polyorder=3, axis=0)\n",
        "\n",
        "      # calculate vel_x and vel_y according to localX and localY for all vehicles\n",
        "      all_veh = []\n",
        "\n",
        "      for i in range(7) :\n",
        "        vel_x = (frame[1:,0+i*4]-frame[:-1, 0+i*4])/0.1\n",
        "        vel_avg_x = (vel_x[1:]+vel_x[:-1])/2.0\n",
        "        vel_x1 = [2.0*vel_x[0]- vel_avg_x[0]]\n",
        "        vel_end_x = [2.0*vel_x[-1]- vel_avg_x[-1]];\n",
        "        vel_x = np.array(vel_x1 + vel_avg_x.tolist() + vel_end_x)\n",
        "\n",
        "        vel_y = (frame[1:,1+i*4]-frame[:-1, 1+i*4])/0.1\n",
        "        vel_avg_y = (vel_y[1:]+vel_y[:-1])/2.0\n",
        "        vel_y1 = [2.0*vel_y[0]- vel_avg_y[0]]\n",
        "        vel_end_y = [2.0*vel_y[-1]-vel_avg_y[-1]]\n",
        "        vel_y = np.array(vel_y1 + vel_avg_y.tolist() + vel_end_y)\n",
        "\n",
        "        if isinstance(all_veh,(list)) :\n",
        "            all_veh = np.vstack((vel_x, vel_y))\n",
        "        else:\n",
        "            all_veh = np.vstack((all_veh, vel_x.reshape(1,-1)))\n",
        "            all_veh = np.vstack((all_veh, vel_y.reshape(1,-1)))\n",
        "\n",
        "      all_veh = np.transpose(all_veh)\n",
        "      total_frame_data = np.concatenate((all_veh[:,:2], frame), axis=1)\n",
        "\n",
        "      # split into several frames each frame have a total length of 100, drop sequence smaller than 130\n",
        "      if total_frame_data.shape[0] < 130 :\n",
        "        continue\n",
        "\n",
        "      X = total_frame_data[:-29,:]\n",
        "      Y = total_frame_data[29:,:4]\n",
        "\n",
        "      count = 0\n",
        "      for i in range(X.shape[0]-100) :\n",
        "        if random.random() > 0.2 :\n",
        "            continue\n",
        "\n",
        "        if count>20:\n",
        "            break\n",
        "\n",
        "        self.frames_x = self.frames_x + [X[i:i+100,:]]\n",
        "        self.frames_y = self.frames_y + [Y[i:i+100,:]]\n",
        "\n",
        "        count += 1\n",
        "\n",
        "  def norm_data(self) :\n",
        "    A = [list(x) for x in zip(*(self.frames_x))]\n",
        "    A = torch.tensor(A, dtype=torch.float32)\n",
        "    A = A.view(-1, A.shape[2])\n",
        "    print(\"A:\", A.shape)\n",
        "\n",
        "    self.mn = torch.mean(A, dim=0)\n",
        "    self.range = (torch.max(A, dim=0).values - torch.min(A, dim=0).values)/2.0\n",
        "    self.range = torch.ones(self.range.shape, dtype=torch.float32)\n",
        "    self.std = torch.std(A,dim=0)\n",
        "    self.frames_x = [(torch.tensor(item, dtype=torch.float32)-self.mn)/(self.std*self.range) for item in self.frames_x]\n",
        "    self.frames_y = [(torch.tensor(item, dtype=torch.float32)-self.mn[:4])/(self.std[:4]*self.range[:4]) for item in self.frames_y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vspmiUfYSI7B"
      },
      "outputs": [],
      "source": [
        "def get_dataloader(opt, csv_path=\"/content/WholeVdata2.csv\") :\n",
        "  \"\"\"\n",
        "  return torch.util.data.Dataloader for train, valid and test\n",
        "  \"\"\"\n",
        "  # load Dataloader\n",
        "  dataset = TrajectoryDataset(csv_path)\n",
        "  with open(\"Dataset.pickle\", \"wb\") as output :\n",
        "      pickle.dump(dataset, output)\n",
        "\n",
        "  # split Dataloader into train test and valid 7:2:1\n",
        "  num_train = int(dataset.__len__()*0.7)\n",
        "  num_test = int(dataset.__len__()*0.9) - num_train\n",
        "  num_valid = int(dataset.__len__() - num_test - num_train)\n",
        "  train, valid, test = torch.utils.data.random_split(dataset, [num_train, num_valid, num_test])\n",
        "\n",
        "  # create dataloader instance\n",
        "  train_dataloader = DataLoader(train, batch_size=opt[\"batch_size\"], shuffle=True, drop_last=True)\n",
        "  valid_dataloader = DataLoader(valid, batch_size=opt[\"batch_size\"], shuffle=False, drop_last=False)\n",
        "  test_dataloader = DataLoader(test, batch_size=opt[\"batch_size\"], shuffle=False, drop_last=False)\n",
        "\n",
        "  return train_dataloader, valid_dataloader, test_dataloader, dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy34HugSWRAk"
      },
      "source": [
        "## **Trajectory LSTM Model 클래스 정의**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDpCAvdpTqSz"
      },
      "outputs": [],
      "source": [
        "class TrajectoryLSTM(nn.Module) :\n",
        "  def __init__(self, input_size, target_size, hidden_size, num_layer, p) :\n",
        "    # Inheritance\n",
        "    super(TrajectoryLSTM, self).__init__()\n",
        "\n",
        "    # Create LSTM Layer Instance\n",
        "    self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=num_layer, bidirectional=False, batch_first=True, dropout=p)\n",
        "    self.bilstm = nn.LSTM(hidden_size, hidden_size//2, num_layers=num_layer, bidirectional=True, batch_first=True, dropout=p)\n",
        "\n",
        "    # Create FC Layer Instance\n",
        "    self.input2lstm = nn.Linear(input_size, hidden_size)\n",
        "    self.input2bilstm = nn.Linear(input_size, hidden_size)\n",
        "    self.fc0 = nn.Linear(hidden_size, 128)\n",
        "    self.fc1 = nn.Linear(128, 64)\n",
        "    self.fc2 = nn.Linear(64, target_size)\n",
        "    self.input2output = nn.Linear(input_size, 64)\n",
        "\n",
        "    # Create Activation Layer Instance\n",
        "    self.act = nn.Tanh()\n",
        "\n",
        "  def forward(self, input) :\n",
        "    lstmOutput, _ = self.lstm(self.input2lstm(input))\n",
        "    bilstmOutput, _ = self.bilstm(self.input2bilstm(input))\n",
        "\n",
        "    output = self.act(self.fc0(lstmOutput + bilstmOutput))\n",
        "    output = self.act(self.fc1(output)) + self.input2output(input)\n",
        "    output = self.fc2(output)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wam4_wUMpm-u"
      },
      "source": [
        "## **훈련 및 모델 하이퍼파라미터 선정**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVZ4xPiEpsRb"
      },
      "outputs": [],
      "source": [
        "opt = {\"input_size\":30, \"target_size\":4, \"hidden_size\":256, \"num_layer\":5, \"p\":0.1,\n",
        "       \"batch_size\":128, \"num_epoch\":50, \"lr\":1e-3, \"seed\":42}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9Oo8RG1OG-H"
      },
      "source": [
        "## **Seed 고정**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwBQCHkrOIez"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXxYOkYOOZvP"
      },
      "outputs": [],
      "source": [
        "def fix_seed(seed) :\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEoLg6GYSp1Y"
      },
      "source": [
        "## **훈련 과정 요약을 위한 Average Meter 인스턴스 생성**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RdmSTR8SrFh"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object) :\n",
        "  def __init__(self) :\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self) :\n",
        "    self.val = 0\n",
        "    self.avg = 0\n",
        "    self.sum = 0\n",
        "    self.count = 0\n",
        "\n",
        "  def update(self, val, n=1) :\n",
        "    self.val = val\n",
        "    self.sum += val*n\n",
        "    self.count += n\n",
        "    self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67RTXRutM_cl"
      },
      "source": [
        "## **Trajectory LSTM 모델 훈련**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCclzRVYovLo"
      },
      "source": [
        "### **사용 Device 정하기 (GPU 또는 CPU)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTdQNN6posAg"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkD1lzJro0ih"
      },
      "outputs": [],
      "source": [
        "print(f\"Device Type : {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84E3RWjcS2cN"
      },
      "source": [
        "### **DataLoader 인스턴스 생성**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBy-aY4uS2Fj"
      },
      "outputs": [],
      "source": [
        "train_dataloader, valid_dataloader, test_dataloader, dataset = get_dataloader(opt, \"/content/WholeVdata2.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyN6pZV5M_cl"
      },
      "source": [
        "### **Trajectory LSTM 모델 인스턴스 생성**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeW0uJMJVyVz"
      },
      "outputs": [],
      "source": [
        "fix_seed(opt[\"seed\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3TiYa_PM_cl"
      },
      "outputs": [],
      "source": [
        "model = TrajectoryLSTM(opt[\"input_size\"], opt[\"target_size\"], opt[\"hidden_size\"], opt[\"num_layer\"], opt[\"p\"]).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xs662LSZt_K"
      },
      "source": [
        "### **Trajectory LSTM 모델 파라미터 개수 계산**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUKtw-vCZwaz"
      },
      "outputs": [],
      "source": [
        "num_param = sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrJ3KG1-Z02w"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of Trainable Parameters : {num_param:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM3SkwAWM_cl"
      },
      "source": [
        "### **손실 함수 인스턴스 생성**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcKBayOxM_cl"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0KgGsi-M_cl"
      },
      "source": [
        "### **Optimizer 인스턴스 생성**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bRH6uWLM_cl"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=opt[\"lr\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMcHAiSvfclF"
      },
      "source": [
        "### **훈련 결과 저장을 위한 AverageMeter 인스턴스 생성**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbrNqS0dSruq"
      },
      "outputs": [],
      "source": [
        "train_loss, valid_loss = AverageMeter(), AverageMeter()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97OOUWV2S3rj"
      },
      "source": [
        "### **훈련 결과 저장을 위한 Python List 인스턴스 생성**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXziUEolS3a-"
      },
      "outputs": [],
      "source": [
        "train_loss_list, valid_loss_list = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E8Gbl3IfWPb"
      },
      "outputs": [],
      "source": [
        "best_valid_loss = torch.inf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpbGma7geQuA"
      },
      "source": [
        "### **훈련 진행**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fEta2llWePQx"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, opt[\"num_epoch\"]+1) :\n",
        "  ########################################################################################################################################\n",
        "  train_bar = tqdm(train_dataloader) # Create TQDM Instance\n",
        "  train_loss.reset() # Reset AverageMeter Instance\n",
        "\n",
        "  model.train() # Train Mode\n",
        "\n",
        "  for data in train_bar :\n",
        "    input, target = data # Unpack Tuple Elements\n",
        "    input, target = input.to(device), target.to(device) # Assign Device\n",
        "    optimizer.zero_grad() # Set Gradient to 0\n",
        "    pred = model(input) # Get Prediction\n",
        "    loss = criterion(pred[:,-30:,2:4], target[:,-30:,2:4]) # Compute Loss\n",
        "    loss.backward() # Back-Propagation\n",
        "    optimizer.step() # Update Weight\n",
        "\n",
        "    train_loss.update(loss.detach().cpu().item(), opt[\"batch_size\"]) # Compute Averaged Loss\n",
        "    train_bar.set_description(desc=f\"[{epoch}/{opt['num_epoch']}] [Train] < Loss:{train_loss.avg:.4f} >\")\n",
        "\n",
        "  train_loss_list.append(train_loss.avg)\n",
        "\n",
        "  ########################################################################################################################################\n",
        "\n",
        "  valid_bar = tqdm(valid_dataloader) # Create TQDM Instance\n",
        "  valid_loss.reset() # Reset AverageMeter Instance\n",
        "\n",
        "  model.eval() # Evaulation Mode\n",
        "\n",
        "  for data in valid_bar :\n",
        "    input, target = data # Unpack Tuple Elements\n",
        "    input, target = input.to(device), target.to(device) # Assign Device\n",
        "\n",
        "    with torch.no_grad() :\n",
        "      pred = model(input) # Get Prediction\n",
        "      loss = criterion(pred[:,-30:,2:4], target[:,-30:,2:4]) # Compute Loss\n",
        "\n",
        "      valid_loss.update(loss.detach().cpu().item(), opt[\"batch_size\"]) # Compute Averaged Loss\n",
        "      valid_bar.set_description(desc=f\"[{epoch}/{opt['num_epoch']}] [Valid] < Loss:{valid_loss.avg:.4f} >\")\n",
        "\n",
        "  valid_loss_list.append(valid_loss.avg)\n",
        "\n",
        "  if valid_loss.avg < best_valid_loss :\n",
        "    best_valid_loss = valid_loss.avg\n",
        "    torch.save(model.state_dict(), \"Best-LSTM.pth\")\n",
        "\n",
        "  torch.save(model.state_dict(), \"Latest-LSTM.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LB5fkB6ZYlx"
      },
      "outputs": [],
      "source": [
        "print(f\"Best Valid Loss : {best_valid_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppj6oqU5bO3m"
      },
      "source": [
        "## **Trajectory LSTM 모델 훈련 과정 시각화**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVC7TiX0bW-R"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(opt[\"num_epoch\"]), train_loss_list, label=\"Train Loss\")\n",
        "plt.plot(np.arange(opt[\"num_epoch\"]), valid_loss_list, label=\"Valid Loss\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.title(\"[Trajectory] Train Loss vs. Valid Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPYQzuSMmfIo"
      },
      "source": [
        "## **Trajectory LSTM 모델 추론**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJEQnWCh1eks"
      },
      "source": [
        "### **Best Model 불러오기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3Vd3gBI1La1"
      },
      "outputs": [],
      "source": [
        "weights = torch.load(\"/content/Best-LSTM.pth\")\n",
        "model.load_state_dict(weights, strict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZlism3i4snR"
      },
      "source": [
        "### **전처리에 사용한 통계값 불러오기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZXEV23u37EU"
      },
      "outputs": [],
      "source": [
        "std = dataset.std[:4].to(device)\n",
        "mn = dataset.mn[:4].to(device)\n",
        "rg = dataset.range[:4].to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BML49xMBJuW"
      },
      "source": [
        "### **Trajectory Model 추론 진행**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWcGRK5X6jj5"
      },
      "outputs": [],
      "source": [
        "pred_list, target_list = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF0zozI_1jnp"
      },
      "outputs": [],
      "source": [
        "test_bar = tqdm(test_dataloader) # Create TQDM Instance\n",
        "\n",
        "model.eval() # Evaulation Mode\n",
        "\n",
        "for data in test_bar :\n",
        "  input, target = data # Unpack Tuple Elements\n",
        "  input, target = input.to(device), target.to(device) # Assign Device\n",
        "\n",
        "  with torch.no_grad() :\n",
        "    pred = model(input)\n",
        "    pred = (pred*(rg*std) + mn).detach().cpu().numpy()\n",
        "    pred = scipy.signal.savgol_filter(pred, window_length=5, polyorder=2,axis=1)\n",
        "\n",
        "    target = (target*(rg*std)+mn).detach().cpu().numpy()\n",
        "    pred[:,:-30,:] = target[:,:-30,:]\n",
        "\n",
        "    pred_list.append(pred)\n",
        "    target_list.append(target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "383rRCXA6zqG"
      },
      "source": [
        "### **추론 (예측) 결과 시각화**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiZxRdpa62Is"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "index = 0\n",
        "plt.plot(pred_list[0][index,:,2], pred_list[0][index,:,3], \"r\", label=\"Prediction\")\n",
        "plt.plot(target_list[0][index,:,2], target_list[0][index,:,3], \"g\", label=\"Ground-Truth\")\n",
        "plt.xlabel(\"Local X Coordinate\")\n",
        "plt.ylabel(\"Local Y Coordinate\")\n",
        "plt.title(\"Trajectory Prediction\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkvavYqVHXxl"
      },
      "source": [
        "## **Trajectory LSTM 모델 구조를 바꾸어 가면서 성능을 올려보세요**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PtCuljmHa65"
      },
      "outputs": [],
      "source": [
        "# Option Dictionary 입력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlchxL9WAst8"
      },
      "source": [
        "### **Trajectory LSTM Model 클래스 정의**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlU1P160AsuB"
      },
      "outputs": [],
      "source": [
        "# 모델 구조 설계"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5dJzZTaHirG"
      },
      "source": [
        "### **Trajectory LSTM 모델 훈련 (MSE)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRkEHpjeHirK"
      },
      "source": [
        "#### **LSTM 모델 인스턴스 생성**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NmO94mrHirK"
      },
      "outputs": [],
      "source": [
        "# 시드 고정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzXplU_IHirK"
      },
      "outputs": [],
      "source": [
        "# 모델 인스턴스 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDkkWyd3HirK"
      },
      "source": [
        "#### **LSTM 모델 파라미터 개수 계산**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnPIGgovHirK"
      },
      "outputs": [],
      "source": [
        "# 모델 파라미터 계산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ASjsQL0HirK"
      },
      "outputs": [],
      "source": [
        "# 모델 파라미터 개수 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS-_6SJUHirK"
      },
      "source": [
        "#### **손실 함수 인스턴스 생성**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VuUzE3yHirK"
      },
      "outputs": [],
      "source": [
        "# MSE 손실 함수 인스턴스 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb1n677zHirK"
      },
      "source": [
        "#### **Optimizer 인스턴스 생성**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5_VhnaXHirK"
      },
      "outputs": [],
      "source": [
        "# Adam Optimizer 인스턴스 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmi10N2DHirK"
      },
      "source": [
        "#### **훈련 진행**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbkgMWC5HirK"
      },
      "outputs": [],
      "source": [
        "# 모델 훈련 코드 작성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4sOfcC6HirL"
      },
      "source": [
        "### **Trajectory LSTM 모델 훈련 과정 시각화**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RsqqwWjHirL"
      },
      "outputs": [],
      "source": [
        "# 훈련 과정 시각화 코드 작성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcG8Y9NKHirL"
      },
      "source": [
        "### **모델 성능 평가**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL_eMLxyBDtG"
      },
      "source": [
        "#### **Best Model 불러오기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYwhlPCbBDtG"
      },
      "outputs": [],
      "source": [
        "# Best Model 불러오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGSlG_YtBDtH"
      },
      "source": [
        "#### **전처리에 사용한 통계값 불러오기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfRhnuHIBDtH"
      },
      "outputs": [],
      "source": [
        "# 통계값 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o3Ee7EdBP-c"
      },
      "source": [
        "#### **Trajectory Model 추론 진행**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_Scl90gBDtH"
      },
      "outputs": [],
      "source": [
        "# List 인스턴스 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0LCcYrSBDtH"
      },
      "outputs": [],
      "source": [
        "# 모델 추론 진행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzm1V9y9BDtH"
      },
      "source": [
        "#### **추론 (예측) 결과 시각화**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHeN1iPHBDtH"
      },
      "outputs": [],
      "source": [
        "# 예측 결과 시각화"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 1236839,
          "sourceId": 18599,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 29869,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}