{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOfg2bJCc5Bbynj2n0WnCDJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jetsonai/Working-R-Ssaem/blob/main/CNN/%5B4%5D_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **사전 학습된 모델을 활용한 전이학습 (Transfer Learning with Pretrained Network)**"
      ],
      "metadata": {
        "id": "VG5Bu-Kd9-jj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 라이브러리 불러오기"
      ],
      "metadata": {
        "id": "EvASHmatLACE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torchmetrics"
      ],
      "metadata": {
        "id": "JGBmcPTJ9fv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRcMh-6uKTSd"
      },
      "outputs": [],
      "source": [
        "from os import makedirs, listdir\n",
        "from os.path import join\n",
        "\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "from torchmetrics import Accuracy\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 시드 고정"
      ],
      "metadata": {
        "id": "caX_syK3LM0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_seed(seed) :\n",
        "  # Fix Seed\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "ACxI_AumLBko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 손실 함수 및 평가 지표 평균화"
      ],
      "metadata": {
        "id": "A3FJF87wLUhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object) :\n",
        "  def __init__(self) :\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self) :\n",
        "    self.val = 0\n",
        "    self.avg = 0\n",
        "    self.sum = 0\n",
        "    self.count = 0\n",
        "\n",
        "  def update(self, val, n=1) :\n",
        "    self.val = val\n",
        "    self.sum += val*n\n",
        "    self.count += n\n",
        "    self.avg = self.sum/self.count"
      ],
      "metadata": {
        "id": "wmEXfyG3LT_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 시험 데이터셋 다운로드"
      ],
      "metadata": {
        "id": "cPgn9A4S-qPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
        "!unzip -qq cats_and_dogs_filtered.zip"
      ],
      "metadata": {
        "id": "8DZ_vvzN-qPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Custom Dataloader 생성"
      ],
      "metadata": {
        "id": "4-Lk7TGF-qPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## Custom DataLoader ##########\n",
        "class PyTorchCustomDataset(Dataset):\n",
        "  def __init__(self, root_dir=\"cats_and_dogs_filtered/train\", transform=None):\n",
        "    self.image_abs_path = root_dir\n",
        "    self.transform = transform\n",
        "    self.label_list = listdir(self.image_abs_path)\n",
        "    self.label_list.sort()\n",
        "    self.x_list = []\n",
        "    self.y_list = []\n",
        "    for label_index, label_str in enumerate(self.label_list):\n",
        "      img_path = join(self.image_abs_path, label_str)\n",
        "      img_list = listdir(img_path)\n",
        "      for img in img_list:\n",
        "        self.x_list.append(join(img_path, img))\n",
        "        self.y_list.append(label_index)\n",
        "    pass\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_list)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image = Image.open(self.x_list[idx])\n",
        "    if image.mode != \"RGB\":\n",
        "      image = image.convert('RGB')\n",
        "    if self.transform is not None:\n",
        "      image = self.transform(image)\n",
        "    return image, torch.tensor(self.y_list[idx]).type(torch.LongTensor)\n",
        "\n",
        "  def __save_label_map__(self, dst_text_path=\"label_map.txt\"):\n",
        "    label_list = self.label_list\n",
        "    f = open(dst_text_path, 'w')\n",
        "    for i in range(len(label_list)):\n",
        "      f.write(label_list[i]+'\\n')\n",
        "    f.close()\n",
        "    pass\n",
        "\n",
        "  def __num_classes__(self):\n",
        "    return len(self.label_list)"
      ],
      "metadata": {
        "id": "QBT2H5nJ-qPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pretrained Model Parameter 전체를 학습 (Unfrozen Backbone)"
      ],
      "metadata": {
        "id": "EL43AKjG_KYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## Training Code ##########\n",
        "def transfer_learning_unfrozen(model, img_channels=3, img_size=224, num_classes=2, lr=1e-4, total_epochs=20, seed=42, batch_size=16, src=\"cats_and_dogs_filtered\") :\n",
        "    # Load Dataset\n",
        "    train_transform = transforms.Compose([transforms.Resize((img_size, img_size)),\n",
        "                                          transforms.RandomHorizontalFlip(0.5),\n",
        "                                          transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4,\n",
        "                                                                                         saturation=0.2, hue=0.1)], p=0.8),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                               std=[0.229, 0.224, 0.225])]) # ImageNet의 RGB 통계량\n",
        "    test_transform = transforms.Compose([transforms.Resize((img_size, img_size)),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                              std=[0.229, 0.224, 0.225])]) # ImageNet의 RGB 통계량\n",
        "\n",
        "    # Create Custom Dataset Instance\n",
        "    train_dataset = PyTorchCustomDataset(join(src, \"train\"), train_transform)\n",
        "    test_dataset = PyTorchCustomDataset(join(src, \"validation\"), test_transform)\n",
        "\n",
        "    # Fix Seed\n",
        "    fix_seed(seed)\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    # Check Device\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Current Device : {device}\")\n",
        "\n",
        "    # Fix Seed\n",
        "    fix_seed(seed)\n",
        "\n",
        "    # Unfreeze CNN Backbone\n",
        "    for param in model.parameters() :\n",
        "      param.requires_grad = True\n",
        "\n",
        "    # Replace Linear Layer\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, num_classes) # Customize Classifier\n",
        "\n",
        "    # Assign Device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Summarize Model\n",
        "    summary(model, (img_channels, img_size, img_size))\n",
        "\n",
        "    # Create Optimizer Instance\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    # Create Loss Instance\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Create Metric Instance\n",
        "    metric = Accuracy(\"multiclass\", num_classes=num_classes).to(device)\n",
        "\n",
        "    # Create AverageMeter Instance\n",
        "    train_loss, train_acc = AverageMeter(), AverageMeter()\n",
        "    test_loss, test_acc = AverageMeter(), AverageMeter()\n",
        "\n",
        "    # Create List Instance\n",
        "    train_loss_list, train_acc_list = [], []\n",
        "    test_loss_list, test_acc_list = [], []\n",
        "\n",
        "    # Create Directory\n",
        "    ckpt_dir, graph_dir = \"ckpt/backbone_unfrozen\", \"result/backbone_unfrozen\"\n",
        "    makedirs(ckpt_dir, exist_ok=True), makedirs(graph_dir, exist_ok=True)\n",
        "\n",
        "    # Set Best Accuracy\n",
        "    best_acc = 0\n",
        "\n",
        "    # Start Training\n",
        "    for epoch in range(total_epochs) :\n",
        "      # Create TQDM Bar Instance\n",
        "      train_bar = tqdm(train_loader)\n",
        "\n",
        "      # Reset AverageMeter\n",
        "      train_loss.reset(), train_acc.reset()\n",
        "\n",
        "      # Set Training Mode\n",
        "      model.train()\n",
        "\n",
        "      # Training Phase\n",
        "      for data in train_bar :\n",
        "        img, label = data\n",
        "        img, label = img.to(device), label.to(device)\n",
        "\n",
        "        # Update Classifier Weights\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(img)\n",
        "        loss = criterion(pred, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute Metric\n",
        "        acc = metric(pred, label)\n",
        "\n",
        "        # Update AverageMeter\n",
        "        train_loss.update(loss.cpu().item()), train_acc.update(acc.cpu().item())\n",
        "\n",
        "        # Show Training Status\n",
        "        train_bar.set_description(desc=f\"[Train] [{epoch+1}/{total_epochs}] < Loss:{train_loss.avg:.4f} | Acc.:{train_acc.avg:.4f} >\")\n",
        "\n",
        "      # Add Training Loss and Accuracy\n",
        "      train_loss_list.append(train_loss.avg), train_acc_list.append(train_acc.avg)\n",
        "\n",
        "      # Create TQDM Bar Instance\n",
        "      test_bar = tqdm(test_loader)\n",
        "\n",
        "      # Reset AverageMeter\n",
        "      test_loss.reset(), test_acc.reset()\n",
        "\n",
        "      # Evaluate Model\n",
        "      with torch.no_grad() :\n",
        "        # Set Test Mode\n",
        "        model.eval()\n",
        "\n",
        "        for data in test_bar :\n",
        "          img, label = data\n",
        "          img, label = img.to(device), label.to(device)\n",
        "\n",
        "          # Update Classifier Weights\n",
        "          pred = model(img)\n",
        "          loss = criterion(pred, label)\n",
        "\n",
        "          # Compute Metric\n",
        "          acc = metric(pred, label)\n",
        "\n",
        "          # Update AverageMeter\n",
        "          test_loss.update(loss.cpu().item()), test_acc.update(acc.cpu().item())\n",
        "\n",
        "          # Show Training Status\n",
        "          test_bar.set_description(desc=f\"[Test] [{epoch+1}/{total_epochs}] < Loss:{test_loss.avg:.4f} | Acc.:{test_acc.avg:.4f} >\")\n",
        "\n",
        "      # Add Test Loss and Accuracy\n",
        "      test_loss_list.append(test_loss.avg), test_acc_list.append(test_acc.avg)\n",
        "\n",
        "      # Save Network\n",
        "      if test_acc.avg > best_acc :\n",
        "        best_acc = test_acc.avg\n",
        "        torch.save(model.state_dict(), f\"{ckpt_dir}/best.pth\")\n",
        "      torch.save(model.state_dict(), f\"{ckpt_dir}/latest.pth\")\n",
        "\n",
        "      # Plot Training vs. Test Loss Graph\n",
        "      plt.clf()\n",
        "      plt.plot(np.arange(epoch+1), train_loss_list, label=\"Training Loss\")\n",
        "      plt.plot(np.arange(epoch+1), test_loss_list, label=\"Test Loss\")\n",
        "      plt.title(\"Loss (Training vs. Test)\")\n",
        "      plt.xlabel(\"Epoch\"), plt.ylabel(\"Loss\")\n",
        "      plt.legend(loc=\"best\")\n",
        "      plt.savefig(f\"{graph_dir}/loss.png\")\n",
        "\n",
        "      # Plot Training vs. Test Accuracy Graph\n",
        "      plt.clf()\n",
        "      plt.plot(np.arange(epoch+1), train_acc_list, label=\"Training Accuracy\")\n",
        "      plt.plot(np.arange(epoch+1), test_acc_list, label=\"Test Accuracy\")\n",
        "      plt.title(\"Accuracy (Training vs. Test)\")\n",
        "      plt.xlabel(\"Epoch\"), plt.ylabel(\"Accuracy\")\n",
        "      plt.legend(loc=\"best\")\n",
        "      plt.savefig(f\"{graph_dir}/accuracy.png\")"
      ],
      "metadata": {
        "id": "DZq6v6Hw_Mki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련 진행"
      ],
      "metadata": {
        "id": "S-t94uukAQ1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "transfer_learning_unfrozen(model)"
      ],
      "metadata": {
        "id": "2okcl5Py_27X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pretrained Model Parameter 일부만 학습 (Frozen Backbone)"
      ],
      "metadata": {
        "id": "J9jzPJKVAK5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## Training Code ##########\n",
        "def transfer_learning_frozen(model, img_channels=3, img_size=224, num_classes=2, lr=1e-2, total_epochs=10, seed=42, batch_size=16, src=\"cats_and_dogs_filtered\") :\n",
        "    # Load Dataset\n",
        "    train_transform = transforms.Compose([transforms.Resize((img_size, img_size)),\n",
        "                                          transforms.RandomHorizontalFlip(0.5),\n",
        "                                          transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4,\n",
        "                                                                                         saturation=0.2, hue=0.1)], p=0.8),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                               std=[0.229, 0.224, 0.225])]) # ImageNet의 RGB 통계량\n",
        "    test_transform = transforms.Compose([transforms.Resize((img_size, img_size)),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                              std=[0.229, 0.224, 0.225])]) # ImageNet의 RGB 통계량\n",
        "\n",
        "    # Create Custom Dataset Instance\n",
        "    train_dataset = PyTorchCustomDataset(join(src, \"train\"), train_transform)\n",
        "    test_dataset = PyTorchCustomDataset(join(src, \"validation\"), test_transform)\n",
        "\n",
        "    # Fix Seed\n",
        "    fix_seed(seed)\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    # Check Device\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Current Device : {device}\")\n",
        "\n",
        "    # Fix Seed\n",
        "    fix_seed(seed)\n",
        "\n",
        "    # Freeze CNN Backbone\n",
        "    for param in model.parameters() :\n",
        "      param.requires_grad = False\n",
        "\n",
        "    # Replace Linear Layer\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, num_classes) # Customize Classifier\n",
        "\n",
        "    # Assign Device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Summarize Model\n",
        "    summary(model, (img_channels, img_size, img_size))\n",
        "\n",
        "    # Create Optimizer Instance\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    # Create Loss Instance\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Create Metric Instance\n",
        "    metric = Accuracy(\"multiclass\", num_classes=num_classes).to(device)\n",
        "\n",
        "    # Create AverageMeter Instance\n",
        "    train_loss, train_acc = AverageMeter(), AverageMeter()\n",
        "    test_loss, test_acc = AverageMeter(), AverageMeter()\n",
        "\n",
        "    # Create List Instance\n",
        "    train_loss_list, train_acc_list = [], []\n",
        "    test_loss_list, test_acc_list = [], []\n",
        "\n",
        "    # Create Directory\n",
        "    ckpt_dir, graph_dir = \"ckpt/backbone_frozen\", \"result/backbone_frozen\"\n",
        "    makedirs(ckpt_dir, exist_ok=True), makedirs(graph_dir, exist_ok=True)\n",
        "\n",
        "    # Set Best Accuracy\n",
        "    best_acc = 0\n",
        "\n",
        "    # Start Training\n",
        "    for epoch in range(total_epochs) :\n",
        "      # Create TQDM Bar Instance\n",
        "      train_bar = tqdm(train_loader)\n",
        "\n",
        "      # Reset AverageMeter\n",
        "      train_loss.reset(), train_acc.reset()\n",
        "\n",
        "      # Set Training Mode\n",
        "      model.train()\n",
        "\n",
        "      # Training Phase\n",
        "      for data in train_bar :\n",
        "        img, label = data\n",
        "        img, label = img.to(device), label.to(device)\n",
        "\n",
        "        # Update Classifier Weights\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(img)\n",
        "        loss = criterion(pred, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute Metric\n",
        "        acc = metric(pred, label)\n",
        "\n",
        "        # Update AverageMeter\n",
        "        train_loss.update(loss.cpu().item()), train_acc.update(acc.cpu().item())\n",
        "\n",
        "        # Show Training Status\n",
        "        train_bar.set_description(desc=f\"[Train] [{epoch+1}/{total_epochs}] < Loss:{train_loss.avg:.4f} | Acc.:{train_acc.avg:.4f} >\")\n",
        "\n",
        "      # Add Training Loss and Accuracy\n",
        "      train_loss_list.append(train_loss.avg), train_acc_list.append(train_acc.avg)\n",
        "\n",
        "      # Create TQDM Bar Instance\n",
        "      test_bar = tqdm(test_loader)\n",
        "\n",
        "      # Reset AverageMeter\n",
        "      test_loss.reset(), test_acc.reset()\n",
        "\n",
        "      # Evaluate Model\n",
        "      with torch.no_grad() :\n",
        "        # Set Test Mode\n",
        "        model.eval()\n",
        "\n",
        "        for data in test_bar :\n",
        "          img, label = data\n",
        "          img, label = img.to(device), label.to(device)\n",
        "\n",
        "          # Update Classifier Weights\n",
        "          pred = model(img)\n",
        "          loss = criterion(pred, label)\n",
        "\n",
        "          # Compute Metric\n",
        "          acc = metric(pred, label)\n",
        "\n",
        "          # Update AverageMeter\n",
        "          test_loss.update(loss.cpu().item()), test_acc.update(acc.cpu().item())\n",
        "\n",
        "          # Show Training Status\n",
        "          test_bar.set_description(desc=f\"[Test] [{epoch+1}/{total_epochs}] < Loss:{test_loss.avg:.4f} | Acc.:{test_acc.avg:.4f} >\")\n",
        "\n",
        "      # Add Test Loss and Accuracy\n",
        "      test_loss_list.append(test_loss.avg), test_acc_list.append(test_acc.avg)\n",
        "\n",
        "      # Save Network\n",
        "      if test_acc.avg > best_acc :\n",
        "        best_acc = test_acc.avg\n",
        "        torch.save(model.state_dict(), f\"{ckpt_dir}/best.pth\")\n",
        "      torch.save(model.state_dict(), f\"{ckpt_dir}/latest.pth\")\n",
        "\n",
        "      # Plot Training vs. Test Loss Graph\n",
        "      plt.clf()\n",
        "      plt.plot(np.arange(epoch+1), train_loss_list, label=\"Training Loss\")\n",
        "      plt.plot(np.arange(epoch+1), test_loss_list, label=\"Test Loss\")\n",
        "      plt.title(\"Loss (Training vs. Test)\")\n",
        "      plt.xlabel(\"Epoch\"), plt.ylabel(\"Loss\")\n",
        "      plt.legend(loc=\"best\")\n",
        "      plt.savefig(f\"{graph_dir}/loss.png\")\n",
        "\n",
        "      # Plot Training vs. Test Accuracy Graph\n",
        "      plt.clf()\n",
        "      plt.plot(np.arange(epoch+1), train_acc_list, label=\"Training Accuracy\")\n",
        "      plt.plot(np.arange(epoch+1), test_acc_list, label=\"Test Accuracy\")\n",
        "      plt.title(\"Accuracy (Training vs. Test)\")\n",
        "      plt.xlabel(\"Epoch\"), plt.ylabel(\"Accuracy\")\n",
        "      plt.legend(loc=\"best\")\n",
        "      plt.savefig(f\"{graph_dir}/accuracy.png\")"
      ],
      "metadata": {
        "id": "TJEjed5fAMB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련 진행"
      ],
      "metadata": {
        "id": "niSD3fUHAh5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "transfer_learning_frozen(model)"
      ],
      "metadata": {
        "id": "GZYa65kkAh5c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}